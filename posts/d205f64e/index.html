<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0">

<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="manifest" href="/manifest.json">
  <meta name="google-site-verification" content="4x9nh5naIcZcY5E724zToiyhCRmgrZmrzuUXHkxhkgU">
  <meta name="msvalidate.01" content="7C9F9018A6940FE68383AACA35759B24">
  <meta name="baidu-site-verification" content="M6SNHjlHjH">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,300italic,400,400italic,700,700italic%7CNoto+Serif+SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.0.0/css/all.min.css" integrity="sha256-jTIdiMuX/e3DGJUGwl3pKSxuc6YOuqtJYkM0bGQESA4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/green/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"hscyber.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.10.1","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="学习task02，关于模型的建立和训练，免模型预测和控制，预测此处指学习环境的状态转移矩阵，控制则是得到并改进策略并输出最佳结果。">
<meta property="og:type" content="article">
<meta property="og:title" content="强化学习入门（2）">
<meta property="og:url" content="https://hscyber.github.io/posts/d205f64e/">
<meta property="og:site_name" content="Huangs&#39;s Notes">
<meta property="og:description" content="学习task02，关于模型的建立和训练，免模型预测和控制，预测此处指学习环境的状态转移矩阵，控制则是得到并改进策略并输出最佳结果。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://hscyber.github.io/posts/d205f64e/image-20231117204142158.png">
<meta property="article:published_time" content="2023-11-17T13:10:20.000Z">
<meta property="article:modified_time" content="2023-11-17T13:19:41.072Z">
<meta property="article:author" content="huangsh">
<meta property="article:tag" content="强化学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hscyber.github.io/posts/d205f64e/image-20231117204142158.png">


<link rel="canonical" href="https://hscyber.github.io/posts/d205f64e/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://hscyber.github.io/posts/d205f64e/","path":"posts/d205f64e/","title":"强化学习入门（2）"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>强化学习入门（2） | Huangs's Notes</title>
  




<link rel="dns-prefetch" href="https://hsc-yber-comments-2vbu21rti-hscyber.vercel.app/">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Huangs's Notes" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Huangs's Notes</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">明天的事后天就知道了</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-docs"><a href="/docs/" rel="section"><i class="fa fa-book fa-fw"></i>文档</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">91</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">18</span></a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">114</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%8D%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B"><span class="nav-number">1.</span> <span class="nav-text">免模型预测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A8%A1%E6%8B%9F%E4%BC%B0%E8%AE%A1"><span class="nav-number">1.1.</span> <span class="nav-text">蒙特卡洛模拟估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E4%BC%B0%E8%AE%A1"><span class="nav-number">1.2.</span> <span class="nav-text">时序差分估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83"><span class="nav-number">1.3.</span> <span class="nav-text">两种方法的比较</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%8D%E6%A8%A1%E5%9E%8B%E6%8E%A7%E5%88%B6"><span class="nav-number">2.</span> <span class="nav-text">免模型控制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#q-learning-%E7%AE%97%E6%B3%95"><span class="nav-number">2.1.</span> <span class="nav-text">Q-learning 算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="nav-number">2.2.</span> <span class="nav-text">强化学习训练过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%99%BA%E8%83%BD%E4%BD%93"><span class="nav-number">2.3.</span> <span class="nav-text">定义智能体</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E7%8E%AF%E5%A2%83"><span class="nav-number">2.4.</span> <span class="nav-text">定义环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BE%E5%8F%82%E6%95%B0"><span class="nav-number">2.5.</span> <span class="nav-text">设参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83%E5%B9%B6%E5%88%86%E6%9E%90%E7%BB%93%E6%9E%9C"><span class="nav-number">2.6.</span> <span class="nav-text">开始训练并分析结果</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="huangsh"
      src="/uploads/avatar3.jpg">
  <p class="site-author-name" itemprop="name">huangsh</p>
  <div class="site-description" itemprop="description">Stay hungry. Stay foolish.</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">114</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">91</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/HSCyber" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;HSCyber" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/1126456109@qq.com" title="E-Mail → 1126456109@qq.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hscyber.github.io/posts/d205f64e/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar3.jpg">
      <meta itemprop="name" content="huangsh">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Huangs's Notes">
      <meta itemprop="description" content="Stay hungry. Stay foolish.">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="强化学习入门（2） | Huangs's Notes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          强化学习入门（2）
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-11-17 21:10:20" itemprop="dateCreated datePublished" datetime="2023-11-17T21:10:20+08:00">2023-11-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习与深度学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/posts/d205f64e/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/posts/d205f64e/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

		  
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>学习task02，关于模型的建立和训练，<strong>免模型预测和控制</strong>，预测此处指学习环境的状态转移矩阵，控制则是得到并改进策略并输出最佳结果。</p>
<span id="more"></span>
<blockquote>
<p>这一次的task方法的推导部分不少地方暂未走通，简单模型的搭建和运行未开展，后续填坑hh</p>
</blockquote>
<h2 id="免模型预测">免模型预测</h2>
<blockquote>
<p>https://johnjim0816.com/joyrl-book/#/ch4/main</p>
</blockquote>
<p>本章介绍常见的两种<strong>免模型预测</strong>方法，<strong>蒙特卡洛方法(MC)</strong>和<strong>时序差分方法(TD)</strong>。除动态规划之外，基础的强化学习算法都是<strong>免模型的</strong>。</p>
<p>有模型与免模型？预测与控制？</p>
<ul>
<li><p>有模型强化学习指“有环境模型”的强化学习，即状态转移概率已知或预先学习到。优点是节约成本，可以在<strong>不与真实环境交互</strong>的情况下进行学习。</p></li>
<li><p>免模型则直接从与环境的交互中学习，在学习过程中需要与真实环境进行大量的交互。</p></li>
<li><p>预测：免模型事先不知道环境的状态转移概率，因此需要先去<strong>近似环境的状态价值函数——预测过程</strong></p></li>
<li><p>控制：找到一个最优策略，过程通常涉及策略评估和策略改进</p></li>
</ul>
<p>待预测的<strong>状态价值函数</strong>，最优策略、累积回报的<strong>期望</strong>： <span class="math display">\[
\begin{aligned}
V_\pi(s) &amp; =\mathbb{E}_\pi\left[R_{t+1}+\gamma R_{t+2}+\gamma^2 R_{t+3}+\cdots \mid S_t=s\right] \\
&amp; =\mathbb{E}_\pi\left[G_t \mid S_t=s\right]
\end{aligned}
\]</span></p>
<h3 id="蒙特卡洛模拟估计">蒙特卡洛模拟估计</h3>
<p>一种<font color="#dd0000">统计模拟方法</font>，通过多次重复的采样观测来逼近实际状态价值函数</p>
<ul>
<li><p>蒙特卡洛方法的思路是我们可以采样大量的轨迹，对于每个轨迹计算对应状态的回报然后取平均近似，称之为经验平均回报。根据大数定律，只要采样的轨迹数量足够多，计算出的经验平均回报就能趋近于实际的状态价值函数。</p></li>
<li><p>蒙特卡洛方法有一定的局限性，即只适用于有终止状态的马尔可夫决策过程。</p></li>
</ul>
<p><font color="#dd0000">显然，当可能的状况和情况很多的情况下不能直接暴力模拟</font>，实际使用主要包括两种，首次访问蒙特卡洛和每次访问蒙特卡洛。</p>
<ul>
<li>FVMC，先模拟一个完整的回合，然后走一遍t并计算每个状态的回报，只在<strong>第一次遍历到某个状态时</strong>会记录并计算对应的回报</li>
<li>EVMC，每次经过计算都会会记录状态的回报</li>
<li>FVMC 是一种基于回合的增量式方法，具有无偏性和收敛快的优点，但是在状态空间较大的情况下，依然需要训练很多个回合才能达到稳定的结果。而 EVMC 则是更为精确的预测方法，但是<strong>计算的成本相对也更高</strong>。</li>
</ul>
<p>估计值的<strong>迭代更新</strong>：新的估计值&lt;---旧的估计值+步长×（目标值-旧的估计值），表达为公式如下，此处的<span class="math inline">\(\alpha\)</span>相当于深度学习中的<strong>学习率</strong>，G-V即为回报估计的误差error。 <span class="math display">\[
V\left(s_t\right) \leftarrow V\left(s_t\right)+\alpha\left[G_t-V\left(s_t\right)\right]
\]</span></p>
<h3 id="时序差分估计">时序差分估计</h3>
<p>一种<font color="#dd0000">基于经验的动态规划方法</font>，它结合了蒙特卡洛和动态规划的思想。</p>
<ul>
<li>奖励更新过程中使用了<strong>当前</strong>奖励和<strong>后继</strong>状态的估计，因此终止状态需要单独考虑</li>
<li>0步自举（bootstrap）——<span class="math inline">\(TD(0)\)</span>：使用一个状态的估计值来更新该状态的估计值，没有再利用后续状态信息，<span class="math inline">\(r_{t+1}-V\left(s_t\right)\)</span></li>
</ul>
<p><span class="math display">\[
\begin{cases}V\left(s_t\right) \leftarrow V\left(s_t\right)+\alpha\left[r_{t+1}-V\left(s_t\right)\right] &amp; \text { 对于终止状态 } V\left(s_t\right) \\ V\left(s_t\right) \leftarrow V\left(s_t\right)+\alpha\left[r_{t+1}+\gamma V\left(s_{t+1}\right)-V\left(s_t\right)\right] &amp; \text { 对于非终止状态 } V\left(s_t\right)\end{cases}
\]</span> <strong>n 步</strong>时序差分:时序差分方法进一步拓展，自举的步数从0步拓展到n步</p>
<ul>
<li><font color="#dd0000">和蒙特卡洛的联系</font>：<strong>趋近无穷时，就变成了蒙特卡洛方法，因此可以通过调整n实现两种方法的权衡</strong></li>
<li>这个<span class="math inline">\(n\)</span>值具体情况需要具体选取和实验，常见方法：网格搜索、随机搜索、训练自适应选择、交叉验证、经验取值</li>
</ul>
<h3 id="两种方法的比较">两种方法的比较</h3>
<p><font color="#dd0000">时序差分效率更高，受条件的限制更少更灵活，且在马尔可夫环境下有更高的学习效率</font></p>
<ul>
<li>效率：时序差分方法可以在线学习，每走一步就可以更新，效率高。蒙特卡洛方法必须等游戏结束时才可以学习。</li>
<li>时序差分方法可以从不完整序列上进行学习。蒙特卡洛方法只能从完整的序列上进行学习。</li>
<li>时序差分方法可以在连续的环境下（没有终止）进行学习。蒙特卡洛方法只能在有终止的情况下学习。</li>
<li>时序差分方法利用了马尔可夫性质，在马尔可夫环境下有更高的学习效率。蒙特卡洛方法没有假设环境具有马尔可夫性质，利用采样的价值来估计某个状态的价值，在不是马尔可夫的环境下更加有效。</li>
</ul>
<img src="/posts/d205f64e/image-20231117204142158.png" class title="image2">
<h2 id="免模型控制">免模型控制</h2>
<blockquote>
<p>控制，即给定一个马尔可夫决策过程，输出<u>最优策略以及对应的最优价值函数</u></p>
</blockquote>
<h3 id="q-learning-算法">Q-learning 算法</h3>
<h3 id="强化学习训练过程">强化学习训练过程</h3>
<p>首先我们会迭代很多个回合，在每回合中，首先重置环境回到初始化的状态，智能体根据状态选择动作，然后环境反馈中下一个状态和对应的奖励，同时智能体会更新策略，直到回合结束。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i_ep <span class="keyword">in</span> <span class="built_in">range</span>(train_eps): <span class="comment"># 遍历每个回合</span></span><br><span class="line">    <span class="comment"># 重置环境，获取初始状态</span></span><br><span class="line">    state = env.reset()  <span class="comment"># 重置环境,即开始新的回合</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>: <span class="comment"># 对于比较复杂的游戏可以设置每回合最大的步长，例如while ep_step&lt;100，即最大步长为100。</span></span><br><span class="line">        <span class="comment"># 智能体根据策略采样动作</span></span><br><span class="line">        action = agent.sample_action(state)  <span class="comment"># 根据算法采样一个动作</span></span><br><span class="line">        <span class="comment"># 与环境进行一次交互，得到下一个状态和奖励</span></span><br><span class="line">        next_state, reward, terminated, _ = env.step(action)  <span class="comment"># 智能体将样本记录到经验池中</span></span><br><span class="line">        agent.memory.push(state, action, reward, next_state, terminated) </span><br><span class="line">        <span class="comment"># 智能体更新策略</span></span><br><span class="line">        agent.update(state, action, reward, next_state, terminated)  </span><br><span class="line">        <span class="comment"># 更新状态</span></span><br><span class="line">        state = next_state  </span><br><span class="line">        <span class="comment"># 如果终止则本回合结束</span></span><br><span class="line">        <span class="keyword">if</span> terminated:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>强化学习中有几个要素，<font color="#dd0000">智能体、环境、经验池（经回放）</font>，还要考虑一下智能体在强化学习中主要负责哪些工作。</p>
<h3 id="定义智能体">定义智能体</h3>
<ul>
<li>采样动作</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Agent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>():</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample_action</span>(<span class="params">self, state</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 采样动作，训练时用</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.sample_count += <span class="number">1</span></span><br><span class="line">        <span class="comment"># epsilon是会递减的，这里选择指数递减</span></span><br><span class="line">        self.epsilon = self.epsilon_end + (self.epsilon_start - self.epsilon_end) * math.exp(- self.sample_count / self.epsilon_decay) </span><br><span class="line">        <span class="comment"># e-greedy 策略</span></span><br><span class="line">        <span class="keyword">if</span> np.random.uniform(<span class="number">0</span>, <span class="number">1</span>) &gt; self.epsilon:</span><br><span class="line">            action = np.argmax(self.Q_table[<span class="built_in">str</span>(state)]) <span class="comment"># 选择Q(s,a)最大对应的动作</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            action = np.random.choice(self.n_actions) <span class="comment"># 随机选择动作</span></span><br><span class="line">        <span class="keyword">return</span> action     </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>预测动作，测试不需要额外探索，直接输出Q值对应最大的动作</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Agent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>():</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_action</span>(<span class="params">self,state</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 预测或选择动作，测试时用</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        action = np.argmax(self.Q_table[<span class="built_in">str</span>(state)])</span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>更新方法</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, state, action, reward, next_state, terminated</span>):</span><br><span class="line">    Q_predict = self.Q_table[<span class="built_in">str</span>(state)][action] </span><br><span class="line">    <span class="keyword">if</span> terminated: <span class="comment"># 终止状态</span></span><br><span class="line">        Q_target = reward  </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Q_target = reward + self.gamma * np.<span class="built_in">max</span>(self.Q_table[<span class="built_in">str</span>(next_state)]) </span><br><span class="line">    self.Q_table[<span class="built_in">str</span>(state)][action] += self.lr * (Q_target - Q_predict)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="定义环境">定义环境</h3>
<blockquote>
<p>当然大多数情况下需要根据需求建立我们自己的环境，这时我们也可以仿照 Gym 的模式来做</p>
</blockquote>
<p>我们选择的环境是 OpenAI Gym 开发的，它提供了一套标准化的环境，包括经典的控制理论问题和游戏，代码封装得也比较好，只需要一行代码就能定义好环境，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env = gym.make(<span class="string">&#x27;CliffWalking-v0&#x27;</span>)  </span><br></pre></td></tr></table></figure>
<p>获取环境的状态数和动作数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n_states = env.observation_space.n <span class="comment"># 状态数</span></span><br><span class="line">n_actions = env.action_space.n <span class="comment"># 动作数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;状态数：<span class="subst">&#123;n_states&#125;</span>， 动作数：<span class="subst">&#123;n_actions&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="设参数">设参数</h3>
<p>Q-learning 算法的超参数（需要人工调整的参数）比较少，其中 折扣因子比较固定，设置在 0.9 到 0.999 之间，一般设置成 0.99 即可。而学习率 在本章节中设置的比较大，为 0.1，实际更复杂的环境和算法中学习率是小于 0.01，因为太大很容易发生过拟和的问题，只是本节的环境和算法都比较简单，为了收敛得更快点所以设置得比较大。此外由于我们探索策略中的<span class="math inline">\(\epsilon\)</span>是会随着采样步数衰减的，在实践过程中既不能让它衰减得太快也不能让它衰减得太慢，因此需要合理设置如下参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.epsilon_start = <span class="number">0.95</span> <span class="comment">#  e-greedy策略中epsilon的初始值</span></span><br><span class="line">self.epsilon_end = <span class="number">0.01</span> <span class="comment">#  e-greedy策略中epsilon的最终值</span></span><br><span class="line">self.epsilon_decay = <span class="number">200</span> <span class="comment">#  e-greedy策略中epsilon的衰减率</span></span><br></pre></td></tr></table></figure>
<h3 id="开始训练并分析结果">开始训练并分析结果</h3>
<p>Q-learning</p>
<p>Sarsa</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>huangsh
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://hscyber.github.io/posts/d205f64e/" title="强化学习入门（2）">https://hscyber.github.io/posts/d205f64e/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 强化学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/bcf963a4/" rel="prev" title="强化学习入门（1）">
                  <i class="fa fa-chevron-left"></i> 强化学习入门（1）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/d9c0291/" rel="next" title="Windows安装ubuntu子系统及python环境">
                  Windows安装ubuntu子系统及python环境 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">huangsh</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">244k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">3:42</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.7/pdfobject.min.js","integrity":"sha256-ph3Dk89VmuTVXG6x/RDzk53SU9LPdAh1tpv0UvnDZ2I="},"url":"/lib/pdf/web/viewer"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>



  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/quicklink@2.2.0/dist/quicklink.umd.js" integrity="sha256-4kQf9z5ntdQrzsBC3YSHnEz02Z9C1UeW/E9OgnvlzSY=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://hscyber.github.io/posts/d205f64e/"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<script class="next-config" data-name="waline" type="application/json">{"lang":"en","enable":true,"serverURL":"https://hsc-yber-comments-2vbu21rti-hscyber.vercel.app/","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":true,"pageview":false,"locale":{"placeholder":"Please use international networks. 评论功能大陆网屏蔽"},"avatar":"mm","meta":["nick","mail"],"pageSize":10,"visitor":false,"comment_count":false,"requiredFields":[],"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","el":"#waline","comment":true,"path":"/posts/d205f64e/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>
